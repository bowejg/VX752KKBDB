# ICG Part II

0:00
what would I felt like I really wanted to do this and test it out.

0:04
I would challenge your thoughts around speed as being the benefit.

0:09
But that's up for.

0:11
We can talk about that another time but and I suspected that other I.

0:17
C.

0:17
G.

0:18
Consultants would want to give this a well and I kind of thought lucy we could put a shout out to our people and explain what we're doing and invite them to to take take part.

0:36
I thought it would be a fairly simple thing from our point of view so that the I.

0:40
C.

0:40
G.

0:40
Would just facilitate the group of people that said yes please.

0:43
And then the I.

0:44
C.

0:44
G.

0:44
Would step back and then the people that are taking part would have the relationship with Jack and Alex and that's how I would see it working.

0:53
So it's kind of a member benefit that we're putting it in front of them.

0:56
And simple as that.

1:01
And I think it's interesting too that maybe Jack and Alex might want to look at different types of qualitative researchers because you mentioned off the top of the back user testing.

1:13
So that's U.

1:14
X.

1:14
That's the type of research but there's loads of different types of research.

1:20
So we could maybe some call some different qualitative methodologies or approaches like group discussions for example you could there could be some brand research where somebody was trying to help a brand reposition and that's very different from U.

1:40
X.

1:41
Because that's kind of under getting under what brand imagery and people's associations with brands all of that so there could be different.

1:49
You could maybe if you want to try and have different types of research going on to see when it did and didn't work or you could go the other way and you could try and have a UX examples and then do it in a more consolidated way.

2:06
So we could kind of figure out the approach or probably when we see who says yes I'm up for it then you could see what their profiles were and I could help you figure that out.

2:16
Yeah I think it's exactly those sort of insights that we're hoping to glean from this just to understand the space of veteran and where we kind of fit into it.

2:24
Yeah I put together a kind of one pages so I meant to send it for the call, ended up kind of finishing it quite late last night That I thought might be might be helpful just to kind of they convey the I guess kind of convey where we're at so that that's the sort of summary about us.

2:43
And then I guess in terms of like the inside of the problem we feel like we've sort of seen it it seems like you know analyzing data is quite manual and time consuming a lot of the tools that are available offer like a small improvement but quite complicated to use and so people it seems like people are resorting to still resorting to things like Excel just to kind of get through it because it's it's just familiar and it's not really, you know, there isn't much of a learning curve or alternatively there are sort of black box solutions that you know, try and use ai to give you like kind of unexplainable or sometimes superficial insights that don't really leave you with much kind of ownership of weathers came about.

3:24
I put in some examples from some other kind of products that are out there, like I feel like in vivo is probably a prime example of that, that sort of thing.

3:34
This is like a brief description about our product as it currently is.

3:40
but obviously that's kind of something that we want to iterate and work on and that would be the kind of motivation behind doing this research.

3:46
So you can kind of see roughly how it works there in action.

3:50
It's basically like a chat, but you can ask it questions about some data you've uploaded and it will try and identify themes and give you some sort of analysis of it and by clicking on these links you can sort of see what the references are for anything that anything that it's kind of provided is as feedback and then this is a sort of brief, like discussion around what we won't be aiming to get out of the study and then here I've just written down some of the questions that are like outstanding for us that we want to we want to try and answer.

4:24
So I guess a quick summary that like I think we've shown people like the M.

4:29
V.

4:29
P.

4:29
And I think there's definitely like a lot of there's definitely very positive reaction to But I feel like reading between the lines we wonder whether whether we're kind of wondering whether is it actually the best like ux solution or is it more alluding to the point that what we're showing people is a very simple interface and that's actually more kind of indicative of the problem they're facing the existing tools rather than validation of this is the solution.

5:00
And then you know on top of that like as I mentioned before we've kind of internally tested it's promising but like we need to we need to get a better idea of like what sort of questions people really ask because it's not like these things you know they you can kind of use them in an open ended way and you can be like you can do okay at a very large range of tasks or you can constrain them and you can do really well.

5:22
Like a smaller range of tasks and I think I think I've realized I've been playing with Jack chat GPT.

5:27
And it's how you frame the question is super important isn't it?

5:31
So I guess that kind of helping people get the most out of the tool and understanding when it's really good is potentially part of the offer.

5:42
Yeah.

5:43
Yeah.

5:43
Yeah.

5:44
And then and then on top of that too, like you guys super familiar with like a lot of the data types, people are using a very like multimodal, it's like photos, it's videos, it's audios, images and as like it's not super clear to us here, like how like a chat interface with like interact with those things and so that's something that we want to explore two.

6:04
And then another thing as well, there's a lot of the final reports or presentations people submit are you know, they're they're obviously they're very formal and structured and we're kind of wondering how best to go from, you know, say we did have a very effective chat to face or something else.

6:21
What how do you prevent that from becoming like a bottleneck towards people presenting those insights?

6:27
and then the last thing we were wondering is like do the views our attitudes towards these existing tools change with like larger teams and organizations?

6:35
is it the case that they end up just kind of biting the bullet with like the learning curve of these things and kind of just training everyone to use them, how does that kind of vary I guess so that I guess a sort of overview of like who we are, what we're trying to do and what sort of problems you've encountered and how we're hoping to get some help from our point of view.

6:55
There would also be a question and I guess it should be in there for you guys as well about monetizing, how would you charge the end user and and so I guess you could be asking them about how what would be acceptable to them as an as an added value.

7:15
And then obviously the question reverses, what would you charge us?

7:22
And I think, I think that would be quite important because at the end of the day we're all selling our services to our clients.

7:34
and I think it would give you an indication of who who would buy like who your market is, is it people like us or are you going to be selling?

7:45
I don't know, I can't, I can't imagine that sort of stuff, but maybe a big company like bain or an IPs offs or WPP, you know, like it's sort of where will you put your, will you sell once or whether you sell 100,000 times, I guess.

8:00
This is the kind of question, isn't it?

8:01
Yeah, exactly, I think, understanding how people think about value and like what it means, what I guess what it means for everyone's like bottom line if like to to be more effective these kind of tasks, I guess.

8:17
Yeah, what's different about, I know our members are going to say, what's different about this versus chat GPT.

8:25
And in my my where I've got to my mind is it's about the input that the input is uniquely the stuff of the research.

8:34
But does it use a similar kind of approach?

8:37
Not that I would understand how chat works in any way, but is it similar to But def Yeah, so it's it's the same like foundational technology, I would say that the value add that we're providing is that we've kind of created an interface like back in the facility for it to run over your data as opposed to the information that it's inherently trained on.

9:03
So chat GPT was trained on a bunch of textual data from the internet up to about 2021 but it doesn't know anything about the context of the problems that you're trying to solve all the evidence that you're aware of.

9:17
And so our value add is is creating a system whereby you can use the power of these models but in a way that's contextualized and runs on your data, can I ask a question about that?

9:33
So typically we do a small number of interviews to say we were doing, I don't know 20 interviews, like I'm doing a project at the moment and it's 24 depth interviews, so you'll get a lot of words But it's still 20 like so chat gpt.

9:52
That was the Internet, wasn't it?

9:55
Like that's a lot of data versus our limited data, but is that the kind of thing you need to test to see whether small samples but with lots of words can still deliver in useful insight.

10:09
So we we would not need to train like in the sort of computer science, machine learning sense on like a large set of data.

10:23
there's a kind of intricacy to the way that these things work.

10:27
It's the technical term is like a few shot learning and basically it's called few shot learning like a few shot learning whereby you can get, you can get you can we get a point where you can get very decent like task specific specialization at something with, you know, with with as few as like sort of 33 to 6 examples.

10:55
And that's like the kind of the the the like the selection and implementation of those is sort of becoming like a whole kind of engineering skill and discipline in itself and that that's like kind of what that answering, answering these types of questions about like, you know, what what sorts of things people want to know and how they're going to use it helps us understand the best way to construct those examples specific.

11:25
It's really interesting, I don't know if this is going through lucy's head, but it's almost like partly we're playing with the people that are gonna make us redundant.

11:34
I don't view it like that because I think there's always room for a human brain, but it feels like it's getting a bit close to the edge of that.

11:42
I was thinking an interesting way of using this would be to do the traditional analysis and then run it.

11:50
Yeah, exactly.

11:53
Oh my God, it's saying something different than what I was thinking was that I did a project for Slimming World like in the summer.

12:03
So we've got all of the data, we've done all of the analysis already and we might be able to, but I would have to approach them and ask them whether they'd be willing and they're really, really confidential.

12:18
They'd like really, so I suspect that actually they on the one hand, they'd be really interested in.

12:23
On another hand, they might say no because of the confidentiality and the kind of.

12:27
Nds so, and that does leave another another question around confidentiality.

12:33
Because I think you guys should require quite a lot of confidentiality from us.

12:40
We're going to have to require a lot of confidentiality from you as well because this will be this will be data.

12:49
Like if if I did the Slimming World example, that's their stuff, they own it.

12:54
So we'll have to get clients to agree.

12:57
And but also you don't want us running off and telling other people about what you're doing either, Do you, do you?

13:07
I mean, I feel like yeah.

13:14
No for example, I've got a really good friend who's an engineer who works in your space.

13:21
You wouldn't want me to talk to him about it, would you?

13:24
Yeah, I mean I think, I think like you know in some sense like we it's a sort of concern that we had early on with our first product for the most part, I think generally like the markets where there are good ideas like really vast and actually like even if you look at like a really large company like netflix, right?

13:46
they actually only own like 10% of the streaming market even though like their household name.

13:51
And so I feel like the question around competition is obviously like, a you know, is like a relevant one.

14:00
But you know, I think at the same time as long as there isn't like I guess I don't think, I think we find people knowing about it.

14:06
I think just as long as there isn't like an antagonism towards like I don't know, I guess like you know, as long as I don't interfere with like us being able to kind of do productive research and have conversations with people and I think it's fine.

14:21
Like I have a question about almost protecting your product in terms of what involvement will you have with participant participants as they're going through the process because what I would hate is for people to have not such a good experience and then you not to be able to communicate well.

14:45
We could do this, we could do this or have you thought about this as it could potentially damage a future client of yours at this point.

14:57
So I feel like you ought to have a lot of involvement with with our members.

15:03
Yeah.

15:04
We're, me and Jack have been discussing this and we're pretty open minded about the level of interaction we have.

15:10
We even discussed potentially helping some people on a project doing free labor and just working with the tour and seeing how it might assist.

15:17
So willing to do anything really that your members need to reiterate a bit.

15:24
So rather than like dive in with 10 or 12 people maybe you do a couple of people first see how that works with them and then do it.

15:37
You know, I don't know how much speed you need, like are you urgent about this or are you how are you trying to progress it?

15:45
We we are like main thing right now is just like really really being very first principles and making sure that we like just just do the proper research.

15:56
It's like for us it's like slowing down to speed up.

15:58
I think if you if you try and run with like the wrong assumptions then you can run up huge bills with like engineering or trying to sell something people don't want or and so I think for us like I think I think that that sounds pretty optimal.

16:11
I think what you described like I think using, having tested the tool on some of our own data, I would say that like you know, one in 51 in five things it's coming out with right now are like really good, but then I think the other, the other other types of responses we're getting are like I think it's at the stage, it's at the stage right now where I think I think if we were to just give it to people with the response would probably be like, yeah, I guess it's cool but like, I don't know, you know, I don't think there'd be much, I think it would probably just, you know, we'd probably burn some leads and then and then I think, you know what will be great would be as Alex kind of just sort of outlined like just doing some real sort I guess, fieldwork on our side and like literally almost going and working with some people, we were kind of talking about this yesterday, like we would be like more than happy to like actors like free labor, if any any anyone your members wants, you know, wants to people to help analyze stuff just so you can understand the problem better.

17:10
I think that would that would be amazing.

17:12
And I think if you position it like this is I think from most of our members are kind of my my age were more sort of as kind of this is really early, minimum viable product stage, I'm gonna start going around going on vP all the time, most valuable player now, minimal viable anyway wherever and we're working.

17:41
I think this could be an amazing, we'll pitch this as a collaboration to for the betterment of, you know, rather than kind of, but I think people like me will probably be really excited to get in on the ground floor of it and obviously it gives us an opportunity to kind of shape what it could, what it could be like.

18:03
I'm also personally just really intrigued by it and there'll be loads of people in the I C G I'm imagining lucy that will also have that point of view, do you think?

18:15
Absolutely.

18:17
But yeah, I was just thinking as well, we do have some tech focused members as well, I assume.

18:28
I don't know whether we're going to weed them out or whether you want the people like Kath absolutely fascinated and don't know the first thing about it or you want those that might even be developing something similar we spoke to in terms of people we spoke to Richard Owen.

18:49
I think he's sort of he's more like yesterday he's kind of more like he's more sort of tech focused and I think he was like a really good example because he just he explained to us, he's just joined the like innovation team like a larger, like a larger brand and you know, his remit was kind of look at like he's his experience to look at like tools that could transform their their work process and so he's kind of doing a lot of evaluation of these things, so I think that would be super helpful.

19:21
Yeah, I'm trying to think what sort of what's the kind of best way to approach it, I think I would say in summary, I don't think, I think we're super worried about competition.

19:34
I think I think there's a lot of space to play as long as as long as it doesn't become antagonistic.

19:40
and I think that if we could try and if I think for us, if you have to prioritize or kind of index for like I guess diversity of of people to speak to, so you can see the process that different stages on different types of projects.

19:59
And I think that would be that would be like the most helpful and what do they need to come with you talking about some transcripts in a very basic level.

20:13
So I think stage stage one of this would basically the absolute ideal situation would be that like Alex or I or both of us literally go and meet with with somebody in person and kind of either work with them like help them out with something or just you know, kind of see how they're working a little bit you know in person and kind of make make some observations that way You know, do do a few sessions like that, take that back to our kind of engineering team, like share some of the insights that we found about like exactly how people are conducting these types of studies, like what sorts of questions they are trying to answer, how in a practical sense they would actually start to use this thing.

20:57
We iterated on a solution, designed something, come back to them and then and then and then do some like kind of more in depth testing ideally with the same people and get a sense of like whether whether we've made meaningful improvement and then I think maybe you imagine do that sort of the issue with that.

21:18
Jack, that sounds amazing and I'm like I'm definitely wanna call straight forward for all of that.

21:25
The only issue is of course streets typical, we've got all different kinds of members, so some of our members just work for other researchers, other research agencies and some of them are micro agencies like me.

21:41
So like at the moment I think what you're describing is get to understand Call Street and what Call Street does and what kinds of projects it has and how it could help.

21:52
I'd be completely up for that.

21:54
The issue we would have is like, I'm writing proposal for for Kellogg's about one of their big selling brands that's in decline at the moment and they want to get under the hood of their users.

22:13
I would love to like do that project with you, but I'd have to just be an N.

22:18
D.

22:19
A.

22:19
On every single client issue because because which is kind of fine, like you could work with Coal Street and then I'd approach every single client that we're working with and some will say no and some will say yes, if that makes sense.

22:36
Or you could just pick some individual projects and work on individual projects.

22:44
There's there's different ways to go and you, the thing is that what Coal Street does is really different from what another agency does.

22:54
We've all become a bit niche I suppose.

22:56
So I do a lot of food an FM fast moving consumer goods stuff like everyday life bits and bobs, Liz Montgomery, who I know she'd be really into this, she does tech stuff, so she works for tech clients and more business to business well world.

23:20
So I don't know whether the whole agency and kind of like shadowing the whole agency model would totally work, but it might do.

23:29
I almost wonder whether you want to pick a few varied projects to follow people on because that might be more straightforward because then it's one client approach one N.

23:41
D.

23:41
A.

23:42
and then you might get 10 projects that you're shadowing and working on and 10 different agencies so you're and then maybe you need to regroup and then kind of figure out whether you want to shadow an agency for a while.

24:01
You see what I'm saying.

24:02
It's like you can take all your time up with call straight, not all your time, but I don't think you could have 10 agencies if that makes sense.

24:12
Okay.

24:13
I think that's probably that sounds like a good refinement then to focus on the project level.

24:17
I think particularly in in like the I guess like privacy.

24:21
Nd a point as you say like one approach I think would massively simplify things.

24:25
Yeah I think if yeah if if if it's possible to do that and I guess index for that like diversity.

24:34
So we can see like a range of different a range of different examples of study then a sort of I think I feel like it would be okay to be Maybe I don't I don't know, maybe maybe this is kind of to my own ignorance but it feels like perhaps like sector agnostic would be okay.

24:53
As long as it's like maybe maybe I don't know, I guess the question for you guys, do you think it would be valuable to look at it to break that down by sector or by like type of type of project or or those things sort of interrelated, cutting the other thing that's striking me is feel like you're going to have to do this in a bit of a suck it and see how much time you've got kind of a way and whether you want to do them all at the same time and then you've kind of, you're gonna have to be servicing people that's in a stacking sort of way or whether it would be a bit kind of like, right, we'll go with call Streets projects on X and then we'll go with Liz project on why and then we'll go with matt's projects on or whether you could do a few at the same time.

25:44
And and so I don't know whether it's sector or methodology.

25:48
I think you might have to take a bit of a iterative right, let's do this now.

25:54
Let's do this.

25:55
And and kind of what we got is our offer approach.

25:58
Sorry, I'm being a bit vague, but I'm not sure we can answer that till we sort of see what's on the table for you from our members and that's sort of a bit dependent on what they're doing at the moment.

26:13
But also some agencies have like very limited methodologies.

26:21
Some agencies have really broad methodologies and different sectors.

26:26
I'm sorry, I'm being really woefully, but it's all very individual?

26:31
I think we have a real struggle if we were to kind of when we try to categorize things, we've tried to say, well, what do our members mainly due in terms of their methodology?

26:41
What do our members mainly due in terms of their sector?

26:44
And it's actually quite hard to do, isn't it, lucy bit muddled and a bit messy.

26:51
Yeah, I'm just thinking about our members needs as well in terms of what would be most appealing to them.

27:03
I am wondering whether you can try and knit the work together so you might work, we say three and then those three come together and almost have a mini group discussion with you because I think that would be quite useful for our members to almost nosy about other people's work.

27:26
So they're getting that better and you are getting sort of almost like castle earlier collaborative thinking.

27:32
Yeah.

27:33
And then they'll come up with a few thoughts and ideas for, you will learn stuff.

27:37
We'll probably be able to refine what questions worked and which didn't as well.

27:45
I suspect it's going to be down to the way you ask the machine things and that a lot of the effectiveness of the tool will be around that in the at least in the early days, I would think, knowing what you want from it, I suspect.

28:04
But I don't know.

28:07
and that will also then help you how into how you position it.

28:13
It might be speed, but I'm not sure that speed.

28:18
Mean speed is always the thing that you get.

28:26
academics take a really long time over stuff.

28:29
We already kind of work at speed anyway as well, because they kind of pick through the bones of everything in a way that we don't because we're commercial.

28:40
Yeah.

28:40
I feel like if it's yeah, it seems like there's a there's a kind of agree, there's a sort of agreement around like how the research will be deployed and used.

28:52
And so there's often there's I guess there's a commercial objective, right?

28:54
And it's kind of clear what you need to do to get there versus in academia where it's like, it feels far more like explore a tive and and how it like how it's going to fit into like a massive picture of other sort of work and publication rather than the commercial stuff is how can I sell more and I need to learn that by this date.

29:18
You know, ultimately like it's dressed up in a lot of other fluffy things, but so it's much more pragmatic.

29:30
yeah, I think yeah, sort of like rule of thumb really with this is like, you know, I think the things that like, I suppose I tend to do well, I guess from your experience of our product and like, you know, talking to other other folks is just like you can you can you really meaningfully meaningfully provide like a tenfold advantage in in like on some sort of access and, you know, and and exactly what that applies to vary by the industry and for some it could be speed for us, a cost, perhaps perhaps quality or I think it's like we rely on our brains to come up with the answer and there's always the niggle, it's like, am I really biased, have I missed something really important and asking the computer?

30:28
I think to kind of give there what they, what they see as the patterns.

30:37
I just would find that massively reassuring and it could be, I do think it's short cutting in some way, but it's almost like it's short cutting and it's more robust of both things at the same time.

30:51
It's kind of, it's kind of like having someone just to chat and almost getting a second opinion further thought it's down to the research of the person to make those recommendations and present the insight, You know, if the computer you're not going to necessarily rely on what's coming out from yours.

31:14
But it will stimulate further thinking.

31:16
I think 100% I think it's an Ally, it's that kind of, you know, sort of objective ally, disinterested Ally as well, which is also useful because sometimes we get a bit in the head of our clients and we we kind of nudge the answer towards.

31:39
There's a lot of wishful thinking in the world of business and sometimes you kind of get a little bit pulled along towards what they want.

31:49
So I watched this did a marketing course and there was a really famous case study of levi's where they all convinced themselves that they could go into the male suit market.

32:02
And then the qualitative researcher was sort of trying to temper it and kind of go, well maybe you need to start out with sports jackets first of all and you can kind of see that that they didn't want to listen to the research, they didn't want to hear what people were saying, but also that everybody had just really wanted the thing to happen.

32:24
And I guess because we're humans we can get pulled along by that and they would almost be this brilliant way of pulling things back a bit.

32:31
So let's get real that I think would be really helpful.

32:35
The computer says no.

32:37
And then look at why.

32:40
Yeah, I think that that would be my kind of somebody else might just go amazing.

32:47
We'll just put it through the computer and the computer will give us the results tomorrow.

32:51
And we're in a hurry.

32:52
Speed might be what some people really go for.

32:56
There's also different.

32:59
There's there's also this like I guess there's this, there's one thing we've seen that I suppose it's become a bit of a theme in the in the space with like, you know, ai augmented working is like kind of the 90 10 approach where people are like it's great for like throwing me this first draft.

33:18
And I know it's like basically the sort of subordinate junior machine that's like produced this thing.

33:24
But now because now because it's taken me this far it means I can take it that far when I do the deep thinking this shallow stuff.

33:34
Yeah.

33:34
Yeah exactly.

33:36
That's another way.

33:37
Another way people think about it.

33:40
How are we going to progress?

33:43
Are we going to invite people to a meeting like this for you to talk about your product?

33:51
We're going to present it in a recent way and invite people in.

33:57
I think we should, sorry, I would quite like us to somehow give everybody the opportunity to, to read the brief and then apply and then we maybe then everyone meets you answer questions and then we select after.

34:20
That would be my ideal.

34:21
So there's a bit of a kind of a process that we do it by.

34:26
Yeah, I think I think that would definitely work.

34:29
I can send you guys this brief here and if you have any like comments or feedback, I feel like it's probably there's probably minimal detail on like exactly like what involvement we required or like what the study would look like.

34:43
I think we've kind of developed a little bit this conversation about, you know, maybe a part one being, seeing how people work and then going off and then coming back again and bring the tool and I feel like if we kind of outlined that a bit further we could kind of I could send this draft over and then we could after this call we could kind of work in a bit more of a description of how we like to run the study.

35:03
And I imagine you guys would probably have enormous value to add their two and kind of advising us on like how how how we could actually get the most out of it too.

35:11
And so we could just do I guess a kind of quick turnaround on that and then and then it'll probably be in a position where if you if you were happy to maybe you know to kind of reach out to a few a few members you think might be interested in.

35:23
and then and then kind of discuss it through on a call that would be great.

35:27
I'd also love us too when we've done the trial, share the findings with our broader members and other people in the research by a community because we could make quite a lot of noise about this that would be beneficial to the I.

35:42
C.

35:42
G.

35:42
And to you guys.

35:44
That's the end result that we kind of share sort of kind of where we got to if we're all happy that it got to a good place obviously we have to do that if we feel like oh no it's too early days but I would be really keen to, I think that would be fantastic.

36:02
I think I could see it being a really good, really good content piece, like a write up of this and for like, for like publicity too.

36:09
Like we got, we got Techcrunch once and like, I think it's, it can be huge, like the sort of, the impact and the visibility and you know, again, if that's a good, like, synergy for you guys and I think we'd be very, very open to that, which would be open to that lucy because that's me.

36:25
Absolutely, it's very nice to be able to do this.

36:29
We don't have to jump through many hoops to help with this.

36:36
So yeah, I think it'll be great.

36:40
I think it's so exciting and interesting and amazing.

36:45
Yeah, I'm really excited to have, I really, really want to be on the trial.

36:50
Like I will have a massive hissy fit if you don't let me try it.

36:56
I think that's some really supportive of you and thank you.

37:00
Thanks for thanks your enthusiasm.

37:01
I think it's been yeah, really, really, really inspiring for us and I think it definitely feels like we're done going down an interesting and interesting part here, I think kind of looking into this lucy, I hope we're not the people that killed qualitative research, that how did it all go wrong?

37:20
Like we said, we're just enhancing qualities already cath whether we say yes or not, nothing to do with.

37:33
Okay, fair enough.

37:34
Let it it's interesting actually there's lots of there's lots of articles and I heard something the radio as well the other day about how chat is affecting the education system and yeah I had I had Inside Science on Radio four.

37:51
They were yeah it was really it was I was really interesting actually and I think how how there's a review now of like how assessment works and and and responding to that disruption I guess.

38:02
And I think you know I think I think yeah you could I think I feel like I don't think they'll ever replace it but I feel like I think there's a really great opportunity to get on get on the wagon early and kind of be a Trailblazer and helps us.

38:19
We've been trying out chat duty so we got a brief and we we asked chad some questions about it was espresso and then we spoke to our client about the brand and actually there was quite a big difference in what chap G.

38:37
P.

38:38
T.

38:38
Told us and what the client told us and it's like the trouble with it is it all seems so plausible and Ray loves plausible doesn't it?

38:48
So the thing that makes me uncomfortable is that you can you you read it and you're like oh now that's the truth and it's just it's just information isn't it?

39:00
That's it in a plausible way and that worries me.

39:07
What I like about this is it feels contained within the data that you're giving it.

39:13
So if it spouts out a load of nonsense fine it's not useful but at least there's some kind of parameters maybe around it that feel a bit different.

39:26
So the plausibility he would be from within, I don't know if I'm right on that.

39:30
Yeah.

39:31
No you're right.

39:32
It's kind of that there's a sort of skeptic movement as well within like in the sort of tech world people that don't believe the way that you know ai is developing is actually gonna is actually gonna lead us to what we think and they refer to these things as semantic parrots.

39:50
Yeah.

39:50
Like it's a parrot that's learned to say so much stuff that it can sound plausible but it has no idea what it's talking about.

39:56
I think that's that's actually true.

39:58
That's not even skeptical.

39:59
That's just true isn't it?

40:00
Yeah.

40:01
Moment.

40:02
That's what it is, isn't it?

40:03
Yeah.

40:04
It's I mean it's it's really interesting, there's this guy as recline he runs a podcast about this and it's like you know it gets very philosophical like the boundaries of like what what what's what even is our internal representation of what we think we know like to what to what extent are we also like a I mean essentially it's trained to convince humans of its truthfulness rather than actually being true.

40:28
So it will go out of its way to sound like it's telling you the right thing even if it's just making stuff up and that's that's what it's rewarded on because the whole chat style technology is basically can I convince a human that I'm a real thing?

40:42
Speaking?

40:42
Yeah.

40:43
Yeah.

40:43
Yeah.

40:44
Yeah.

40:45
I mean that's so interesting isn't it?

40:47
That's what Children do isn't it?

40:49
When they're developing they are romantic parrots to some degree.

40:53
And then one of the key differences with kids as well is that we're actually capable of something called like symbolic learning to sew.

41:02
No one no one ever told, no one's ever told us all of the numbers between one and a million.

41:06
But we can discern a pattern from seeing it enough times to be able to count all the way there without like they're probably numbers between one and a million.

41:14
I've never said in my life but I can say them.

41:18
I don't know what they are because I don't understand how the sequence works.

41:22
But.

41:29
Okay.

41:31
Really great.

41:32
So you're going to send this to us.

41:34
Probably work on a refined version.

41:37
Well then when you've worked on the refined version, well we'll send you back on comments and then if this is lucy is in agreement with this we'll we'll send an invitation to people to read the brief and to apply.

41:53
And then we will bring together the applicants to have more of a conversation with them with you.

41:59
So it'll be like a big group discussion and and then we will we you will make your selection.

42:08
That that would be perfect.

42:10
Yeah we'll we'll get that we'll get that turn around then as soon as possible and send you on a brief.

42:15
And I think I think that sounds like a great set of next steps.

42:19
I think it would be really useful for us Kath as well for all the applicants to check their profiles on the I.

42:24
C.

42:24
G.

42:25
Website.

42:26
It's a good excuse isn't it because we were nudging them the whole time but you need to be able to look at them understand them.

42:33
So a condition of employment will be that everybody has to have their profile up to date so that you guys can I like you thinking lucy including a photo.

42:47
Yes absolutely.

42:49
Got to be some kind of way of getting them to do it.

42:54
That's that's that's fine.

42:57
As long as we communicate to our members right up front that they may not get chosen.

43:02
They may not get chosen.

43:04
And also this is very early days so they shouldn't expect it to be.

43:10
We're helping iron out we're looking for failure.

43:14
We're helping to improve.

43:15
We're not we're not testing an end product here.

43:19
Absolutely.

43:20
Yeah I think that's exactly it's like he's like you know he's a sort of demo demo of the capabilities I guess.

43:29
My final solution to the to the sort of to the problem solving is, you know, might look might look very different by the end of it, merely interested in, yeah, getting the deepest possible understanding of what that could look like.

43:45
Great stuff.

43:48
Lovely to see you again, both.

43:50
Really nice.

43:51
Thank you again, and thanks for your support.

43:54
So far it's been it's been really great chatting with you guys and looking forward to working together.

43:59
Okay, see you later.
